{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "import string\n",
    "import re\n",
    "#from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer as VS\n",
    "from textstat.textstat import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train/training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=df.tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Davidson Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "other_exclusions = [\"#ff\", \"ff\", \"rt\"]\n",
    "stopwords.extend(other_exclusions)\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "def preprocess(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, '', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, '', parsed_text)\n",
    "    return parsed_text\n",
    "\n",
    "def tokenize(tweet):\n",
    "    \"\"\"Removes punctuation & excess whitespace, sets to lowercase,\n",
    "    and stems tweets. Returns a list of stemmed tokens.\"\"\"\n",
    "    tweet = \" \".join(re.split(\"[^a-zA-Z]*\", tweet.lower())).strip()\n",
    "    tokens = tweet.split() #[stemmer.stem(t) for t in tweet.split()]\n",
    "    return tokens\n",
    "\n",
    "def basic_tokenize(tweet):\n",
    "    \"\"\"Same as tokenize but without the stemming\"\"\"\n",
    "    tweet = \" \".join(re.split(\"[^a-zA-Z.,!?]*\", tweet.lower())).strip()\n",
    "    return tweet.split()\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=tokenize,\n",
    "    preprocessor=preprocess,\n",
    "    ngram_range=(1, 3),\n",
    "    stop_words=stopwords,\n",
    "    use_idf=True,\n",
    "    smooth_idf=False,\n",
    "    norm=None,\n",
    "    decode_error='replace',\n",
    "    max_features=10000,\n",
    "    min_df=5,\n",
    "    max_df=0.75\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susanabenavidez/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'e', 'f', 'g', 'h', 'j', 'l', 'n', 'p', 'r', 'u', 'v', 'w'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "#Construct tfidf matrix and get relevant scores\n",
    "tfidf = vectorizer.fit_transform(tweets).toarray()\n",
    "vocab = {v:i for i, v in enumerate(vectorizer.get_feature_names())}\n",
    "idf_vals = vectorizer.idf_\n",
    "idf_dict = {i:idf_vals[i] for i in vocab.values()} #keys are indices; values are IDF scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get POS tags for tweets and save as a string\n",
    "tweet_tags = []\n",
    "for t in tweets:\n",
    "    tokens = basic_tokenize(preprocess(t))\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    tag_list = [x[1] for x in tags]\n",
    "    tag_str = \" \".join(tag_list)\n",
    "    tweet_tags.append(tag_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweet_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess for slang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the emoji dataset\n",
    "def load_slang_dict():\n",
    "    slang_dict = {}\n",
    "    with open(\"slang_to_words.txt\", 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            tokens = line.strip().split('\\t')\n",
    "            #print(tokens[1])\n",
    "            slang_dict[tokens[1]] = tokens[0]\n",
    "    return slang_dict\n",
    "slang_dict_one = load_slang_dict()\n",
    "#slang_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the emoji dataset\n",
    "def load_slang_two_dict():\n",
    "    slang_dict_two = {}\n",
    "    with open(\"noslangdotcom.txt\", 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            tokens = line.strip().split(':')\n",
    "            #print(tokens[1])\n",
    "            slang_dict[tokens[0]] = tokens[1]\n",
    "    return slang_dict\n",
    "slang_dict_two = load_slang_two_dict()\n",
    "#slang_dict_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the emoji dataset\n",
    "def load_slang_three_dict():\n",
    "    slang_dict_three = {}\n",
    "    with open(\"internet_slangsDotNet.txt\", 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            tokens = line.strip().split('==')\n",
    "            slang_dict[tokens[0]] = tokens[1]\n",
    "            #print(\"first \", tokens[0], \"second \", tokens[1])\n",
    "    return slang_dict\n",
    "slang_dict_three = load_slang_three_dict()\n",
    "#slang_dict_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "def load_slang_four():\n",
    "    slang_dict_four = {}\n",
    "    with open(\"common_twitter_abbreviations.txt\", 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            tokens = line.strip().split('=')\n",
    "            slang_dict[tokens[0]] = tokens[1]\n",
    "    return slang_dict\n",
    "slang_dict_four = load_slang_four()\n",
    "#slang_dict_four\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hundo p': '100% certain',\n",
       " 'trill': 'real true',\n",
       " 'otp': 'One True Pairing',\n",
       " 'distractivated': 'Distracted in a way that motivates/inspires',\n",
       " 'JOMO': 'Joy of Missing Out',\n",
       " 'tache': 'mustache',\n",
       " 'ngl': 'Not gonna lie',\n",
       " 'sus': 'Suspect',\n",
       " 'AFAIK': 'As Far As I Know',\n",
       " 'AF': '...as fuck',\n",
       " 'AFK': 'Away From Keyboard',\n",
       " 'AIR': 'Am I Right',\n",
       " '<3': 'Love',\n",
       " 'CFATH': 'Chuckling For All to Hear',\n",
       " 'THNX': 'Thanks',\n",
       " 'HAND': 'Have A Nice Day',\n",
       " 'C U': 'See You',\n",
       " 'C U L8R': 'See You Later',\n",
       " 'SWYP': \"So What's Your Problem?\",\n",
       " 'TIME': 'Tears In My Eyes',\n",
       " 'SWAK': 'Sealed With a Kiss',\n",
       " 'hh': 'Haha',\n",
       " 'CHX': 'Chicks',\n",
       " 'KISS': 'Keep It Simple, Stupid',\n",
       " 'SAL': 'Such A Laugh',\n",
       " 'IDK': \"I Don't Know\",\n",
       " 'NP': 'No problem',\n",
       " 'IHNI': 'I have no idea',\n",
       " 'JSYK': 'Just so you know',\n",
       " 'IDC': \"I don't care\",\n",
       " 'KYS': 'Kill yourself',\n",
       " 'ATM': 'At The Moment',\n",
       " 'WYD': 'What Are You Doing',\n",
       " 'WYA': 'Where Are You At',\n",
       " 'IRL': 'In Real Life',\n",
       " 'SWYD': \"Stop What You're Doing\",\n",
       " 'SNOL': 'Said Nice Out Loud',\n",
       " 'BTW': 'By The Way',\n",
       " 'YOYO': \"You're On Your Own\",\n",
       " 'YOLO': 'You Only Live Once',\n",
       " 'ASAP': 'As Soon As Possible',\n",
       " 'OMG': 'Oh My god',\n",
       " 'HAK or XOXO': 'Hugs And Kisses',\n",
       " 'LOL': 'Laughing Out Loud',\n",
       " 'ROTFL': 'Rolling On The Floor Laughing',\n",
       " 'ROFL': 'Rolling On The Floor Laughing',\n",
       " 'WDUM': 'What Do You Mean By That',\n",
       " 'LW': 'Loving The Weather Today',\n",
       " 'LTWT': 'Loving The Weather Today',\n",
       " 'LWT': 'Loving The Weather Today',\n",
       " 'FTW': 'For The Win',\n",
       " 'MSG': 'Message',\n",
       " 'PLZ': 'Please',\n",
       " 'TTYL': 'Talk To You Later',\n",
       " 'ILY': 'I Love You',\n",
       " 'ILU': 'I Love You',\n",
       " 'B/C': 'Because',\n",
       " 'BC': 'Because',\n",
       " 'THX': 'Thank you',\n",
       " 'TU': 'Thank you',\n",
       " 'FYI': 'For Your Information',\n",
       " 'SMH': 'Shaking My Head',\n",
       " 'BFN': 'Bye For Now',\n",
       " 'IMO': 'In My Opinion',\n",
       " 'IMHO': 'In My Honest Opinion',\n",
       " 'BF': 'Boyfriend',\n",
       " 'BFF': 'Best Friend Forever',\n",
       " 'GF': 'Girlfriend',\n",
       " 'SO': 'Significant Other',\n",
       " 'IH8U': 'I Hate You',\n",
       " 'OMFG': 'Oh My Fucking God',\n",
       " 'STFU': 'Shut The Fuck Up',\n",
       " 'WTH': 'What The Hell',\n",
       " 'WTF': 'What The Fuck',\n",
       " 'JK': 'Just Kidding',\n",
       " 'GTFO': 'Get The Fuck Out',\n",
       " 'OTW': 'On The Way',\n",
       " 'YW': \"You're Welcome\",\n",
       " 'TMS': 'That Makes Sense',\n",
       " 'TFW': 'That Feel When',\n",
       " 'TOU': 'Thinking of You',\n",
       " 'TL;DR': \"Too Long; Didn't Read\",\n",
       " 'TLDR': \"Too Long; Didn't Read\",\n",
       " 'TL DR': \"Too Long; Didn't Read\",\n",
       " 'LMAO': '\"Laugh my ass off\"',\n",
       " 'AMAOH': 'A Moderate Amount of Hate',\n",
       " 'W': 'With',\n",
       " 'W/': 'With',\n",
       " 'W/O': 'Without',\n",
       " 'WO': 'Without',\n",
       " 'BRB': 'Be Right Back',\n",
       " 'GG': 'Good Game',\n",
       " 'IACB': \"I ain't coming back\",\n",
       " 'GN': 'Good night',\n",
       " 'GM': 'Good morning',\n",
       " 'TYSM': 'Thank You so Much',\n",
       " 'SM': 'So Much',\n",
       " 'HELLA': 'Very',\n",
       " 'IK': 'I Know',\n",
       " 'UR': 'Your',\n",
       " 'RLY': 'Really',\n",
       " 'b': 'be',\n",
       " 'c': 'see',\n",
       " 'k': 'okay',\n",
       " 'kk': 'okay',\n",
       " 'njoy': 'enjoy',\n",
       " 'nd': 'end',\n",
       " 'o': 'oh',\n",
       " 'r': 'are',\n",
       " 'u': 'you',\n",
       " 'y': 'why',\n",
       " '1': 'won',\n",
       " 'any1': 'anyone',\n",
       " 'ne1': 'anyone',\n",
       " 'no1': 'no one',\n",
       " '2': 'two',\n",
       " '2day': 'today',\n",
       " '2ne': 'tune',\n",
       " '4': 'four',\n",
       " '4get': 'forget',\n",
       " 'a4d': 'afford',\n",
       " '8': '',\n",
       " 'gr8': 'great',\n",
       " 'h8': 'hate',\n",
       " 'ur': \"your and you're\",\n",
       " '1drfl': 'wonderful',\n",
       " 'b4': 'before',\n",
       " 'ez': 'easy',\n",
       " 'sum1': 'someone',\n",
       " 'cu or cya': 'see you',\n",
       " '4u': 'for you',\n",
       " '2mro': 'tomorrow',\n",
       " '2mo': 'tomorrow',\n",
       " 'tmr': 'tomorrow',\n",
       " '+u': 'adieu',\n",
       " 'a$$ ': 'ass',\n",
       " 'a&f ': 'always and forever',\n",
       " \"a'ight \": 'alright',\n",
       " 'a.i.m. ': 'aol instant messanger',\n",
       " 'a/l ': 'age and location',\n",
       " 'a/m ': 'away message',\n",
       " 'a/s/l ': 'age,sex,location',\n",
       " 'a/s/l/p ': 'age/sex/location/picture',\n",
       " 'a/s/l/r ': 'age, sex, location, race',\n",
       " 'a1t ': 'anyone there',\n",
       " 'a3 ': 'anyplace, anywhere, anytime',\n",
       " 'a4u ': 'all for you',\n",
       " 'aaaaa ': 'American Assosciation Against Acronym Abuse',\n",
       " 'aabf ': 'as a best friend',\n",
       " 'aaf ': 'as a friend',\n",
       " 'aak ': 'Alive and Kicking',\n",
       " 'aamof ': 'as a matter of fact',\n",
       " 'aatf ': 'always and totally forever',\n",
       " 'aatw ': 'all around the world',\n",
       " 'abd ': 'Already Been Done',\n",
       " 'abend ': 'absent by enforced net deprivation',\n",
       " 'abft ': 'About fucking Time',\n",
       " 'aboot ': 'about',\n",
       " 'abreev ': 'abbreviation',\n",
       " 'absnt ': 'absent',\n",
       " 'abt ': 'about',\n",
       " 'abwt ': 'about',\n",
       " 'acc ': 'account',\n",
       " 'acct ': 'account',\n",
       " 'acgaf ': \"Absolutely couldn't give a fuck\",\n",
       " 'ack ': 'acknowledged',\n",
       " 'addy ': 'address',\n",
       " 'adhd ': 'Attention Deficit Hyperactivity Disorder',\n",
       " 'adl ': 'all day long',\n",
       " 'admin ': 'administrator',\n",
       " 'adn ': 'any day now',\n",
       " 'aeap ': 'as early as possible',\n",
       " 'af ': 'assface',\n",
       " 'afaiaa ': 'As Far As I Am Aware',\n",
       " 'afaic ': \"as far as I'm concerned\",\n",
       " 'afaicr ': 'As Far As I Can Remember',\n",
       " 'afaicr4 ': 'as far as i can remember for',\n",
       " 'afaics ': 'as far as I can see',\n",
       " 'afaict ': 'as far as I can tell',\n",
       " 'afaik ': 'as far as I know',\n",
       " 'afair ': 'as far as I recall',\n",
       " 'afaiu ': 'As far as I understand',\n",
       " 'afc ': 'away from computer',\n",
       " 'afcpmgo ': 'away from computer parents may go on',\n",
       " 'afg ': 'away from game',\n",
       " 'afk ': 'away from keyboard',\n",
       " 'afkb ': 'away from keyboard',\n",
       " 'agn ': 'again',\n",
       " 'ah ': 'asshole',\n",
       " 'ahole ': 'asshole',\n",
       " 'ai ': 'Artificial Intelligence',\n",
       " 'aiadw ': 'ALL IN A DAYS WORK',\n",
       " 'aiamu ': \"and I'm a monkey's uncle\",\n",
       " 'aicmfp ': 'and I claim my five pounds',\n",
       " 'aight ': 'Alright',\n",
       " 'aightz ': 'alright',\n",
       " 'aiic ': 'as if I care',\n",
       " 'aiid ': 'and if I did',\n",
       " 'aiight ': 'all right',\n",
       " 'aim ': 'AOL instant messanger',\n",
       " 'aimmc ': 'Am I making myself clear',\n",
       " \"ain't \": 'am not',\n",
       " 'aite ': 'Alright',\n",
       " 'aitr ': 'Adult in the room',\n",
       " 'aiui ': 'as I understand it',\n",
       " 'aiws ': 'as i was saying',\n",
       " 'ajax ': 'Asynchronous Javascript and XML',\n",
       " 'aka ': 'also known as',\n",
       " 'akp ': 'Alexander King Project',\n",
       " 'akpcep ': 'Alexander King Project Cultural Engineering Project',\n",
       " 'alaylm ': 'As long as you love me',\n",
       " 'alaytm ': 'as long as you tell me',\n",
       " 'alol ': 'actually laughing out loud',\n",
       " 'alot ': 'a lot',\n",
       " 'alotbsol ': 'always look on the bright side of life',\n",
       " 'alright ': 'all right',\n",
       " 'alrite ': 'Alright',\n",
       " 'alrt ': 'alright',\n",
       " 'alryt ': 'alright',\n",
       " 'ama ': 'ask me anything',\n",
       " 'amf ': 'adios motherfucker',\n",
       " 'amiic ': 'ask me if i care',\n",
       " 'amiigaf ': 'ask me if i give a fuck',\n",
       " 'aml ': 'All My Love',\n",
       " 'ams ': 'Ask me something',\n",
       " 'amsp ': 'ask me something personal',\n",
       " 'anim8 ': 'animate',\n",
       " 'anl ': 'all night long',\n",
       " 'anlsx ': 'Anal Sex',\n",
       " 'anon ': 'anonymous',\n",
       " 'anuda ': 'another',\n",
       " 'anw ': 'anyways',\n",
       " 'anwwi ': 'alright now where was i',\n",
       " 'any1 ': 'Anyone',\n",
       " 'anywaz ': 'anyways',\n",
       " 'aob ': 'any other business',\n",
       " 'aoc ': 'age of consent',\n",
       " 'aoe ': 'Age Of Empires',\n",
       " 'aon ': 'all or nothing',\n",
       " 'aos ': 'adult over shoulder',\n",
       " 'aota ': 'all of the above',\n",
       " 'aoto ': 'Amen on that one',\n",
       " 'aoys ': 'angel on your shoulder',\n",
       " 'api ': 'application program interface',\n",
       " 'apoc ': 'apocalypse',\n",
       " 'apod ': 'Another Point Of Discussion',\n",
       " 'app ': 'application',\n",
       " 'appt ': 'appointment',\n",
       " 'aprece8 ': 'appreciate',\n",
       " 'apreci8 ': 'appreciate',\n",
       " 'apu ': 'as per usual',\n",
       " 'aqap ': 'as quick as possible',\n",
       " 'ar ': 'are',\n",
       " 'arnd ': 'around',\n",
       " 'arse ': 'ass',\n",
       " 'arsed ': 'bothered',\n",
       " 'arvo ': 'afternoon',\n",
       " 'asafp ': 'as soon as fucking possible',\n",
       " 'asaik ': 'as soon as I know',\n",
       " 'asap ': 'as soon as possible',\n",
       " 'asarbambtaa ': 'All submissions are reviewed by a moderator before they are added.',\n",
       " 'asbmaetp ': 'Acronyms should be memorable and easy to pronounce',\n",
       " 'ase ': 'age, sex, ethnicity',\n",
       " 'asf ': 'and so forth',\n",
       " 'ashl ': 'asshole',\n",
       " 'ashole ': 'asshole',\n",
       " 'asic ': 'application specific integrated circuit',\n",
       " 'asl ': 'age, sex, location',\n",
       " 'asln ': 'age, sex, location, name',\n",
       " 'aslo ': 'age sex location orientation',\n",
       " 'aslop ': 'Age Sex Location Orientation Picture',\n",
       " 'aslp ': 'age, sex, location, picture',\n",
       " 'aslr ': 'age sex location race',\n",
       " 'aslrp ': 'age, sex, location, race, picture',\n",
       " 'asr ': 'age sex race',\n",
       " 'asshle ': 'asshole',\n",
       " 'atab ': \"Ain't That A bitch\",\n",
       " 'atb ': 'all the best',\n",
       " 'atfp ': 'answer the fucking phone',\n",
       " 'atl ': 'atlanta',\n",
       " 'atm ': 'at the moment',\n",
       " 'ato ': 'against the odds',\n",
       " 'atop ': 'at time of posting',\n",
       " 'atp ': 'answer the phone',\n",
       " 'atq ': 'answer the question',\n",
       " 'atst ': 'At the same time',\n",
       " 'attn ': 'attention',\n",
       " 'attotp ': 'At The Time Of This Post',\n",
       " 'atw ': 'All the way',\n",
       " 'aty ': 'according to you',\n",
       " 'audy ': 'Are you done yet?',\n",
       " 'aufm ': 'are you fucking mental',\n",
       " 'aufsm ': 'are you fucking shiting me',\n",
       " 'aup ': 'acceptable use policy',\n",
       " 'aupi ': 'and your point is',\n",
       " 'av7x ': 'avenged sevenfold',\n",
       " 'avgn ': 'Angry Video Game Nerd',\n",
       " 'avie ': 'Avatar',\n",
       " 'avsb ': 'a very special boy',\n",
       " 'avtr ': 'avatar',\n",
       " 'avvie ': 'avatar',\n",
       " 'avy ': 'Avatar',\n",
       " 'awb ': 'Acquaintance with benefits',\n",
       " 'awes ': 'awesome',\n",
       " 'awk ': 'awkward',\n",
       " 'awol ': 'absent without leave',\n",
       " 'awsic ': 'and why should i care',\n",
       " 'awsm ': 'awesome',\n",
       " 'awsome ': 'awesome',\n",
       " 'awty ': 'are we there yet',\n",
       " 'ayagob ': 'are you a girl or boy',\n",
       " 'ayb ': 'All Your Base',\n",
       " 'aybab2m ': 'all your base are belong 2 me',\n",
       " 'aybab2u ': 'All your base are belong to us',\n",
       " 'aybabtg ': 'All Your Base Are Belong To Google',\n",
       " 'aybabtu ': 'all your base are belong to us',\n",
       " 'ayc ': 'awaiting your comments',\n",
       " 'ayd ': 'are you done',\n",
       " 'aydy ': 'are you done yet',\n",
       " 'ayec ': 'at your earliest convenience',\n",
       " 'ayfk ': 'are you fucking kidding',\n",
       " 'ayfkm ': 'are you fucking kidding me',\n",
       " 'ayfr ': 'are you for real',\n",
       " 'ayfs ': 'Are You fucking Serious',\n",
       " 'ayk ': 'are you kidding',\n",
       " 'aykm ': 'are you kidding me',\n",
       " 'ayl ': 'are you listening',\n",
       " 'aymf ': 'are you my friend',\n",
       " 'ayok ': 'are you okay',\n",
       " 'aypi ': 'and your point is',\n",
       " 'ayrft ': 'Are you ready for Tomorrow',\n",
       " 'ays ': 'are you serious',\n",
       " 'aysm ': 'are you shitting me?',\n",
       " 'ayst ': 'are you still there',\n",
       " 'ayt ': 'are you there',\n",
       " 'ayte ': 'alright',\n",
       " 'aytf ': 'are you there fucker',\n",
       " 'ayty ': 'are you there yet',\n",
       " 'ayw ': 'as you wish',\n",
       " 'azhol ': 'asshole',\n",
       " 'azn ': 'asian',\n",
       " 'azz ': 'ass',\n",
       " \"Ya'll \": 'You all',\n",
       " 'bi ': 'bye',\n",
       " 'b& ': 'banned',\n",
       " \"b'day \": 'birthday',\n",
       " 'b-cuz ': 'because',\n",
       " 'b-day ': 'birthday',\n",
       " 'b.f.f. ': 'best friend forever',\n",
       " 'b.s. ': 'bullshit',\n",
       " 'b/c ': 'because',\n",
       " 'b/cos ': 'because',\n",
       " 'b/g ': 'background',\n",
       " 'b/s/l ': 'Bisexual/Straight/Lesbian',\n",
       " 'b/t ': 'between',\n",
       " 'b/w ': 'between',\n",
       " 'b00n ': 'new person',\n",
       " 'b00t ': 'boot',\n",
       " 'b0rked ': 'broken',\n",
       " 'b1tch ': 'bitch',\n",
       " 'b2b ': 'business to business',\n",
       " 'b2u ': 'back to you',\n",
       " 'b2w ': ' Back to work',\n",
       " 'b3 ': 'be',\n",
       " 'b4 ': 'before',\n",
       " 'b4n ': 'bye for now',\n",
       " 'b4u ': 'before you',\n",
       " 'b4ug ': 'before you go',\n",
       " 'b4ul ': 'before you Leave',\n",
       " 'b8 ': 'bait',\n",
       " 'b82rez ': 'Batteries',\n",
       " 'b8rez ': 'Batteries',\n",
       " 'b@ ': 'banned',\n",
       " 'bab ': 'Big ass Boobs',\n",
       " 'babi ': 'baby',\n",
       " 'bae ': 'before anyone else',\n",
       " 'baf ': 'bring a friend',\n",
       " 'baggkyko ': 'be a good girl, keep your knickers on',\n",
       " 'bah ': \"I don't really care\",\n",
       " 'bai ': 'Bye',\n",
       " 'bak ': 'back',\n",
       " 'bakk ': 'back',\n",
       " 'balz ': 'balls',\n",
       " 'bamf ': 'bad ass mother fucker',\n",
       " 'bamofo ': 'bitch ass mother fucker',\n",
       " 'bau ': 'back at you',\n",
       " 'bb ': 'bye bye',\n",
       " 'bb4h ': 'bros before hoes',\n",
       " 'bb4n ': 'Bye-bye for now',\n",
       " 'bbbj ': 'Bare Back Blow Job',\n",
       " 'bbe ': 'baby',\n",
       " 'bbf ': 'best boy friend',\n",
       " 'bbfn ': 'Bye Bye for now',\n",
       " 'bbfs ': 'best boyfriends',\n",
       " 'bbfu ': 'be back for you',\n",
       " 'bbg ': 'baby girl',\n",
       " 'bbi ': 'Baby',\n",
       " 'bbiab ': 'be back in a bit',\n",
       " 'bbiaf ': 'be back in a few',\n",
       " 'bbialb ': 'Be back in a little bit',\n",
       " 'bbiam ': 'be back in a minute',\n",
       " 'bbias ': 'be back in a second',\n",
       " 'bbiaw ': 'be back in a while',\n",
       " 'bbifs ': 'be back in a few seconds',\n",
       " 'bbilb ': 'be back in a little bit',\n",
       " 'bbilfm ': 'be back in like five minutes',\n",
       " 'bbim ': 'Be Back In Minute',\n",
       " 'bbk ': 'be back, ok?',\n",
       " 'bbl ': 'be back later',\n",
       " 'bbl8a ': 'Be Back Later',\n",
       " 'bblig ': 'Be back later...i guess',\n",
       " 'bbm ': 'BlackBerry Messenger',\n",
       " 'bbml ': 'be back much later',\n",
       " 'bbn ': 'be back never',\n",
       " 'bbol ': 'be back online later',\n",
       " 'bbp ': 'Banned by parents',\n",
       " 'bbq ': 'be back quick',\n",
       " 'bbrs ': 'be back really soon',\n",
       " 'bbs ': 'be back soon',\n",
       " 'bbsts ': 'be back some time soon',\n",
       " 'bbt ': 'be back tomorrow',\n",
       " 'bbtn ': 'be back tonite',\n",
       " 'bbvl ': 'Be Back Very Later',\n",
       " 'bbw ': 'be back whenever',\n",
       " 'bbwb ': 'best buddy with boobs',\n",
       " 'bbwe ': 'be back whenever',\n",
       " 'bbwl ': 'be back way later',\n",
       " 'bby ': 'baby',\n",
       " 'bbz ': 'babes',\n",
       " 'bc ': 'because',\n",
       " 'bch ': 'bitch',\n",
       " 'bck ': 'back',\n",
       " 'bcnu ': 'be seeing you',\n",
       " 'bcnul8r ': 'be seeing you later',\n",
       " 'bcoz ': 'Because',\n",
       " 'bcurl8 ': \"Because you're late.\",\n",
       " 'bcuz ': 'because',\n",
       " 'bd ': 'birthday',\n",
       " 'bday ': 'birthday',\n",
       " 'bdfl ': 'Benevolent Dictator For Life',\n",
       " 'be4 ': 'before',\n",
       " 'beatch ': 'bitch',\n",
       " 'bebe ': 'baby',\n",
       " 'becuse ': 'because',\n",
       " 'becuz ': 'because',\n",
       " 'beech ': 'bitch',\n",
       " 'beeoch ': 'bitch',\n",
       " 'beezy ': 'bitch',\n",
       " 'beotch ': 'bitch',\n",
       " 'besos ': 'kisses',\n",
       " 'bestie ': 'best friend',\n",
       " 'betch ': 'bitch',\n",
       " 'betcha ': 'bet you',\n",
       " 'bettr ': 'better',\n",
       " 'bewb ': 'boob',\n",
       " 'bewbs ': 'boobs',\n",
       " 'bewbz ': 'boobs',\n",
       " 'bewt ': 'boot',\n",
       " 'beyatch ': 'bitch',\n",
       " 'beyotch ': 'bitch',\n",
       " 'bezzie ': 'best friend',\n",
       " 'bf ': 'boyfriend',\n",
       " \"bf's \": \"boyfriend's\",\n",
       " 'bf+gf ': 'boyfriend and girlfriend',\n",
       " 'bf4e ': 'best friends for ever',\n",
       " 'bf4eva ': 'Best Friends forever',\n",
       " 'bf4l ': 'best friends for life',\n",
       " 'bfam ': 'brother from another mother',\n",
       " 'bfd ': 'big fucking deal',\n",
       " 'bfe ': 'Bum fuck Egypt',\n",
       " 'bff ': 'best friend forever',\n",
       " 'bffa ': 'best friends for always',\n",
       " 'bffaa ': 'Best Friends Forever And Always',\n",
       " 'bffae ': 'Best Friends Forever And Ever',\n",
       " 'bffaw ': 'best friends for a while',\n",
       " 'bffe ': 'Best friends forever',\n",
       " 'bffeae ': 'Best Friend For Ever And Ever',\n",
       " 'bffene ': 'Best Friends For Ever And Ever',\n",
       " 'bffl ': 'best friends for life',\n",
       " 'bffn ': 'best friends for now',\n",
       " 'bfftddup ': 'best friends forever till death do us part',\n",
       " 'bfg ': 'big fucking gun',\n",
       " 'bfh ': 'bitch from hell',\n",
       " 'bfhd ': 'big fat hairy deal',\n",
       " 'bfitww ': 'best friend in the whole world',\n",
       " 'bfn ': 'bye for now',\n",
       " 'bfs ': 'Boyfriends',\n",
       " 'bft ': 'big fucking tits',\n",
       " 'bg ': 'background',\n",
       " 'bh ': 'bloody hell',\n",
       " 'bhwu ': 'back home with you',\n",
       " 'biab ': 'back in a bit',\n",
       " 'biach ': 'bitch',\n",
       " 'biaf ': 'Back In A Few',\n",
       " 'biatch ': 'bitch',\n",
       " 'bibi ': 'bye bye',\n",
       " 'bibifn ': 'bye bye for now',\n",
       " 'bicbw ': 'but I could be wrong',\n",
       " 'bich ': 'bitch',\n",
       " 'bigd ': 'big deal',\n",
       " 'bii ': 'bye',\n",
       " 'bilf ': \"brother i'd like to fuck\",\n",
       " 'bilu ': 'baby i love you',\n",
       " 'bion ': 'Believe it or not.',\n",
       " 'biotch ': 'bitch',\n",
       " 'bioya ': 'blow it out your ass',\n",
       " 'bish ': 'bitch',\n",
       " 'bisly ': 'but i still love you',\n",
       " 'bitd ': 'back in the day',\n",
       " 'bitz ': 'neighborhood',\n",
       " 'biw ': 'boss is watching',\n",
       " 'biwm ': 'bisexual white male',\n",
       " 'biz ': 'Business',\n",
       " 'bizatch ': 'bitch',\n",
       " 'bizi ': 'Busy',\n",
       " 'biznatch ': 'bitch',\n",
       " 'biznitch ': 'bitch',\n",
       " 'bizzle ': 'bitch',\n",
       " 'bj ': 'blowjob',\n",
       " 'bk ': 'back',\n",
       " 'bka ': 'better known as',\n",
       " 'bl ': 'bad luck',\n",
       " 'bleme ': 'blog meme',\n",
       " 'bleve ': 'believe',\n",
       " 'blg ': 'blog',\n",
       " 'blh ': 'bored like hell',\n",
       " 'bling-bling ': 'jewelry',\n",
       " 'blj ': 'blowjob',\n",
       " 'bljb ': 'Blowjob',\n",
       " 'blk ': 'black',\n",
       " 'blkm ': 'Black Male',\n",
       " 'blnt ': 'Better Luck Next time',\n",
       " 'blog ': 'web log',\n",
       " 'blogger ': 'web logger',\n",
       " 'blu ': 'blue',\n",
       " 'bm ': 'Bite Me',\n",
       " 'bm&y ': 'between you and me',\n",
       " 'bm4l ': 'best mates for life',\n",
       " 'bma ': 'best mates always',\n",
       " 'bmay ': 'between me and you',\n",
       " 'bmf ': 'be my friend',\n",
       " 'bmfe ': 'best mates forever',\n",
       " 'bmfl ': 'best mates for life',\n",
       " 'bmha ': 'bite my hairy ass',\n",
       " 'bml ': 'bless my life',\n",
       " 'bmoc ': 'Big Man On Campus',\n",
       " 'bmttveot ': 'best mates till the very end of time',\n",
       " 'bmvp ': 'be my valentine please',\n",
       " 'bn ': 'been',\n",
       " 'bndm3ovr ': 'Bend me over',\n",
       " 'bng ': 'being',\n",
       " 'bnib ': 'Brand new in Box',\n",
       " 'bnol ': 'be nice or leave',\n",
       " 'bnr ': 'banner',\n",
       " 'bo ': 'body odour',\n",
       " 'boati ': 'Bend Over And Take It',\n",
       " 'bobfoc ': 'Body of Baywatch, Face of Crimewatch',\n",
       " 'bobw ': 'Best of Both Worlds',\n",
       " 'boffum ': 'Both of them',\n",
       " 'bofh ': 'bastard operator from hell',\n",
       " 'bogo ': 'buy one get one',\n",
       " 'bogof ': 'buy one get one free',\n",
       " 'bogsatt ': 'bunch of guys sitting around the table',\n",
       " 'bohic ': 'Bend over here it comes',\n",
       " 'bohica ': 'bend over, here it comes again',\n",
       " 'boi ': 'boy',\n",
       " 'bol ': 'Barking Out Loud',\n",
       " 'bonr ': 'boner',\n",
       " 'boomm ': 'bored out of my mind',\n",
       " 'bord ': 'bored',\n",
       " 'bos ': 'boss over shoulder',\n",
       " 'botoh ': 'but on the other hand',\n",
       " 'bout ': 'about',\n",
       " 'bovered ': 'bothered',\n",
       " 'bowt ': 'about',\n",
       " 'boxor ': 'box',\n",
       " 'bpot ': 'big pair of tits',\n",
       " 'br ': 'bathroom',\n",
       " 'brah ': 'brother',\n",
       " 'brb ': 'be right back',\n",
       " 'brbbrb ': 'br right back bath room break',\n",
       " 'brbf ': 'Be Right Back fucker',\n",
       " 'brbg2p ': 'be right back, got to pee',\n",
       " 'brbigtp ': 'be right back, i got to pee.',\n",
       " 'brbl ': 'be right back later',\n",
       " 'brbmf ': 'be right back mother fucker',\n",
       " 'brbn2gbr ': 'Be right back, I need to go to the bathroom',\n",
       " 'brbs ': 'be right back soon',\n",
       " 'brbts ': 'be right back taking shit',\n",
       " 'brd ': 'bored',\n",
       " 'brfb ': 'be right fucking back',\n",
       " 'brgds ': 'best regards',\n",
       " 'brh ': 'be right here',\n",
       " 'brk ': 'Break',\n",
       " 'bro ': 'brother',\n",
       " 'bros ': 'brothers',\n",
       " 'broseph ': 'brother',\n",
       " 'brover ': 'Brother',\n",
       " 'brt ': 'be right there',\n",
       " 'bruh ': 'brother',\n",
       " 'bruhh ': 'Brother',\n",
       " 'bruv ': 'brother',\n",
       " 'bruva ': 'brother',\n",
       " 'bruz ': 'brothers',\n",
       " 'bs ': 'bullsit',\n",
       " 'bsmfh ': 'bastard System Manager From Hell',\n",
       " 'bsod ': 'blue screen of death',\n",
       " 'bsomn ': 'blowing stuff out my nose',\n",
       " 'bstfu ': 'bitch shut the fuck up',\n",
       " 'bstrd ': 'bastard',\n",
       " 'bsx ': 'bisexual',\n",
       " 'bsxc ': 'be sexy',\n",
       " 'bt ': 'bit torrent',\n",
       " 'btb ': 'by the by',\n",
       " 'btch ': 'bitch',\n",
       " 'btcn ': 'Better than Chuck Norris',\n",
       " 'btd ': 'bored to death',\n",
       " 'btdt ': 'been there done that',\n",
       " 'btdtgtts ': 'Been there, done that, got the T-shirt',\n",
       " 'btfl ': 'beautiful',\n",
       " 'btfo ': 'back the fuck off',\n",
       " 'btfw ': 'by the fucking way',\n",
       " 'bth ': 'be totally honest',\n",
       " 'btias ': 'Be there in a second',\n",
       " 'btm ': 'bottom',\n",
       " 'btr ': 'better',\n",
       " 'bts ': 'be there soon',\n",
       " 'btsoom ': 'Beats The shit Out Of Me',\n",
       " 'bttt ': 'been there, tried that',\n",
       " 'bttyl ': 'be talking to you later',\n",
       " 'btw ': 'by the way',\n",
       " 'btwilu ': 'by the way i love you',\n",
       " 'btwitiailwu ': 'by the way i think i am in love with you',\n",
       " 'btwn ': 'between',\n",
       " 'bty ': 'back to you',\n",
       " 'bubar ': 'bushed up beyond all recognition',\n",
       " 'bubi ': 'bye',\n",
       " 'budzecks ': 'butt sex',\n",
       " 'buhbi ': 'Bye Bye',\n",
       " 'bukket ': 'bucket',\n",
       " 'bur ': 'pussy',\n",
       " 'burma ': 'be undressed ready my angel',\n",
       " 'buszay ': 'busy',\n",
       " 'but6 ': 'buttsex',\n",
       " 'butsecks ': 'butt sex',\n",
       " 'butterface ': 'every thing is hot but her face',\n",
       " 'buwu ': 'breaking up with you',\n",
       " 'bw3 ': 'Buffalo Wild Wings',\n",
       " 'bwim ': 'by which i mean',\n",
       " 'bwoc ': 'Big Woman On Campus',\n",
       " 'bwpwap ': 'back when Pluto was a planet',\n",
       " 'bwt ': 'but when though',\n",
       " 'byak ': 'blowing you a kiss',\n",
       " 'byeas ': 'good-bye',\n",
       " 'byes ': 'bye bye',\n",
       " 'bykt ': 'But you knew that',\n",
       " 'byob ': 'Bring your own Beer',\n",
       " 'byoc ': 'bring our own computer',\n",
       " 'byoh ': 'bring your own high',\n",
       " 'byow ': 'bring your own weed',\n",
       " 'byself ': 'by myself',\n",
       " 'bytabm ': 'beat you to a bloody mess',\n",
       " 'bytch ': 'bitch',\n",
       " 'bz ': 'busy',\n",
       " 'bzns ': 'buisness',\n",
       " 'bzy ': 'busy',\n",
       " 'bzzy ': 'busy',\n",
       " 'c ': 'see',\n",
       " 'c 2 c ': 'cam to cam (webcams)',\n",
       " 'c&c ': 'Command and Conquer',\n",
       " \"c'mon \": 'Come On',\n",
       " 'c-p ': 'sleepy',\n",
       " 'c.y.a ': 'cover your ass',\n",
       " 'c/b ': 'comment back',\n",
       " 'c/t ': \"can't talk\",\n",
       " 'c14n ': 'canonicalization',\n",
       " 'c2 ': 'come to',\n",
       " 'c2c ': 'care to chat?',\n",
       " 'c2tc ': 'cut to the chase',\n",
       " 'c4ashg ': 'care for a shag',\n",
       " 'c4y ': 'cool for you',\n",
       " 'c@ ': 'cat',\n",
       " 'cam ': 'camera',\n",
       " 'cancer stick ': 'cigarette',\n",
       " 'catwot ': 'complete and total waste of time',\n",
       " 'cawk ': 'cock',\n",
       " 'cayc ': 'call at your convenience',\n",
       " 'cb ': 'come back',\n",
       " 'cba ': \"can't be arsed\",\n",
       " 'cbb ': \"can't be bothered\",\n",
       " 'cbf ': 'cant be fucked',\n",
       " 'cbfa ': \"can't be fucking arsed\",\n",
       " 'cbfed ': \"can't be fucked\",\n",
       " 'cbi ': \"can't believe it\",\n",
       " 'ccl ': \"Couldn't Care Less\",\n",
       " 'ccna ': 'Cisco Certified Network Associate',\n",
       " 'cd9 ': 'Code 9 (other people nearby)',\n",
       " 'celly ': 'cell phone',\n",
       " 'cex ': 'sex',\n",
       " 'cexy ': 'sexy',\n",
       " 'cfas ': 'care for a secret?',\n",
       " 'cfid ': 'check for identification',\n",
       " 'cfm ': 'come fuck me',\n",
       " 'cg ': 'Congratulations',\n",
       " 'cgad ': \"couldn't give a down\",\n",
       " 'cgaf ': \"couldn't give a fuck\",\n",
       " 'cgf ': 'cute guy friend',\n",
       " 'ch@ ': 'chat',\n",
       " 'champs ': 'champions',\n",
       " 'char ': 'character',\n",
       " 'cheezburger ': 'cheeseburger',\n",
       " 'chik ': 'chick',\n",
       " 'chilax ': 'chill and relax in one word',\n",
       " 'chillax ': 'chill and relax',\n",
       " 'chillin ': 'relaxing',\n",
       " 'chk ': 'check',\n",
       " 'chohw ': 'Come Hell or high water',\n",
       " 'chr ': 'character',\n",
       " 'chronic ': 'marijuana',\n",
       " 'chswm ': 'come have sex with me',\n",
       " 'chswmrn ': 'come have sex with me right now',\n",
       " 'chu ': 'you',\n",
       " 'chut ': 'pussy',\n",
       " 'cid ': 'consider it done',\n",
       " 'cig ': 'cigarette',\n",
       " 'cigs ': 'cigarettes',\n",
       " 'cihswu ': 'can i have sex with you',\n",
       " 'cihyn ': 'can i have your number',\n",
       " 'cilf ': \"child i'd like to fuck\",\n",
       " 'cing ': 'seeing',\n",
       " 'cis ': 'computer information science',\n",
       " 'ciwwaf ': 'cute is what we aim for',\n",
       " 'cless ': 'clanless',\n",
       " 'clm ': 'Cool Like Me',\n",
       " 'clt ': 'Cool Like That',\n",
       " 'cluebie ': 'clueless newbie',\n",
       " 'cm ': 'call me',\n",
       " 'cma ': 'Cover My ass',\n",
       " 'cmao ': 'Crying My ass Off',\n",
       " 'cmar ': 'cry me a river',\n",
       " 'cmb ': 'comment me back',\n",
       " 'cmbo ': 'combo',\n",
       " 'cmcp ': 'call my cell phone',\n",
       " 'cmeo ': 'crying my eyes out',\n",
       " 'cmh ': 'Call My House',\n",
       " 'cmiiw ': \"correct me if I'm wrong\",\n",
       " 'cmitm ': 'Call me in the morning',\n",
       " 'cml ': 'call me later',\n",
       " 'cml8r ': 'call me later',\n",
       " 'cmliuw2 ': 'call me later if you want to',\n",
       " 'cmn ': 'call me now',\n",
       " 'cmomc ': 'call me on my cell',\n",
       " 'cmon ': 'Come on',\n",
       " 'cmplcdd ': 'complicated',\n",
       " 'cmplte ': 'complete',\n",
       " 'cmptr ': 'computer',\n",
       " 'cms ': 'content management system',\n",
       " 'cmt ': 'comment',\n",
       " 'cmw ': 'cutting my wrists',\n",
       " 'cn ': 'can',\n",
       " 'cnc ': 'Command and Conquer',\n",
       " 'cnt ': \"can't\",\n",
       " 'cob ': 'close of business',\n",
       " 'cod ': 'Call of Duty',\n",
       " 'cod4 ': 'call of duty 4',\n",
       " 'cod5 ': 'call of duty 5',\n",
       " 'codbo ': 'Call of Duty',\n",
       " 'codbo2 ': 'Call of Duty',\n",
       " 'code 29 ': 'moderator is watching',\n",
       " 'code 8 ': 'parents are watching',\n",
       " 'code 9 ': 'Parents are watching',\n",
       " 'code9 ': 'other people near by',\n",
       " 'cof ': 'Crying on the floor',\n",
       " 'coiwta ': 'come on i wont tell anyone',\n",
       " 'col ': 'crying out loud',\n",
       " \"comin' \": 'coming',\n",
       " 'comnt ': 'comment',\n",
       " 'comp ': 'Computer',\n",
       " 'compy ': 'computer',\n",
       " 'congrats ': 'congratulations',\n",
       " 'contrib ': 'contribution',\n",
       " 'contribs ': 'contributions',\n",
       " 'convo ': 'conversation',\n",
       " 'coo ': 'cool',\n",
       " 'cood ': 'could',\n",
       " 'copyvio ': 'copyright violation',\n",
       " 'cos ': 'because',\n",
       " 'cotf ': 'crying on the floor',\n",
       " 'cotm ': 'check out this myspace',\n",
       " 'cowboy choker ': 'cigarette',\n",
       " 'coz ': 'because',\n",
       " 'cp ': 'child porn',\n",
       " 'cpl ': 'Cyber Athlete Professional League',\n",
       " 'cpm ': 'cost per 1000 impressions',\n",
       " 'cptn ': 'captain',\n",
       " 'cpu ': 'computer',\n",
       " 'cpy ': 'copy',\n",
       " 'cr ': \"Can't remember\",\n",
       " 'cr8 ': 'crate',\n",
       " 'crakalakin ': 'happening',\n",
       " 'crazn ': 'crazy asian',\n",
       " 'cre8or ': 'creator',\n",
       " 'crm ': 'customer relationship management',\n",
       " 'crp ': 'crap',\n",
       " 'crs ': \"can't remember shit\",\n",
       " 'crunk ': 'combination of crazy and drunk',\n",
       " 'crzy ': 'crazy',\n",
       " 'cs ': 'Counter-Strike',\n",
       " 'cs': 's ',\n",
       " 'csi ': 'Crime Scene Investigation',\n",
       " 'cskr ': 'cock sucker',\n",
       " 'csl ': \"can't stop laughing\",\n",
       " 'ct ': \"can't talk\",\n",
       " 'ctc ': 'call the cell',\n",
       " 'ctf ': 'capture the flag',\n",
       " 'ctfd ': 'calm the fuck down',\n",
       " 'ctfo ': 'chill the fuck out',\n",
       " 'ctfu ': 'cracking the fuck up',\n",
       " 'ctm ': 'chuckle to myself',\n",
       " 'ctn ': \"can't talk now\",\n",
       " 'ctnbos ': \"can't talk now boss over shoulder\",\n",
       " 'ctncl ': \"Can't talk now call later\",\n",
       " 'ctpc ': 'cant talk parent(s) coming',\n",
       " 'ctpos ': \"Can't Talk Parent Over Sholder\",\n",
       " 'ctrl ': 'control',\n",
       " 'ctrn ': \"can't talk right now\",\n",
       " 'cts ': 'change the subject',\n",
       " 'ctt ': 'change the topic',\n",
       " 'cu ': 'goodbye',\n",
       " 'cu2 ': 'see you too',\n",
       " 'cu2nit ': 'see you tonight',\n",
       " 'cu46 ': 'see you for sex',\n",
       " 'cubi ': 'can you believe it',\n",
       " 'cud ': 'could',\n",
       " 'cuic ': 'see you in class',\n",
       " 'cul ': 'see you later',\n",
       " 'cul83r ': 'See you later',\n",
       " 'cul8er ': 'see you later',\n",
       " 'cul8r ': 'See You Later',\n",
       " 'cul8tr ': 'see you later',\n",
       " 'culd ': 'Could',\n",
       " 'cunt ': 'vagina',\n",
       " 'cuom ': 'see you on monday',\n",
       " 'cuple ': 'couple',\n",
       " 'curn ': 'calling you right now',\n",
       " 'cut3 ': 'cute',\n",
       " 'cuwul ': 'catch up with you later',\n",
       " 'cuz ': 'because',\n",
       " 'cuzz ': 'Because',\n",
       " 'cvq ': 'chucking very quietly',\n",
       " 'cw2cu ': 'can`t wait to see you',\n",
       " 'cwd ': 'comment when done',\n",
       " 'cwm ': 'come with me',\n",
       " 'cwmaos ': 'coffee with milk and one sugar',\n",
       " 'cwot ': 'complete waste of time',\n",
       " 'cwtgypo ': \"can't wait to get your panties off\",\n",
       " 'cwyl ': 'chat with ya later',\n",
       " 'cy2 ': 'see you too',\n",
       " 'cya ': 'goodbye',\n",
       " 'cyal ': 'see you later',\n",
       " 'cyal8r ': 'see you later',\n",
       " 'cyas ': 'see you soon',\n",
       " 'cyb ': 'cyber',\n",
       " 'cybl ': 'call you back later',\n",
       " 'cybr ': 'cyber',\n",
       " 'cybseckz ': 'cyber sex',\n",
       " 'cye ': 'Close Your Eyes',\n",
       " 'cyff ': 'change your font, fucker',\n",
       " 'cyl ': 'see you later',\n",
       " 'cyl,a ': 'see ya later, alligator',\n",
       " 'cyl8 ': 'see you later',\n",
       " 'cyl8er ': 'see you later',\n",
       " 'cylbd ': 'catch ya later baby doll',\n",
       " 'cylor ': 'check your local orhtodox rabbi',\n",
       " 'cym ': 'check your mail',\n",
       " 'cyntott ': 'see you next time on Tech Today',\n",
       " 'cyt ': 'see you tomorrow',\n",
       " 'cyu ': 'see you',\n",
       " 'c|n>k ': 'coffee through nose into keyboard',\n",
       " 'Icydci ': \"In case you didn't catch it\",\n",
       " 'd&c ': 'divide and conquer',\n",
       " 'd&df ': 'drug & disease free',\n",
       " 'd.t.f ': 'down to fuk',\n",
       " 'd.w ': \"don't worry\",\n",
       " 'd/c ': 'disconnected',\n",
       " 'd/l ': 'download',\n",
       " 'd/m ': \"Doesn't Matter\",\n",
       " 'd/w ': \"don't worry\",\n",
       " 'd00d ': 'dude',\n",
       " 'd1ck ': 'dick',\n",
       " 'd2 ': 'Diablo 2',\n",
       " 'd2m ': 'dead to me',\n",
       " 'd2t ': 'drink to that',\n",
       " 'd8 ': 'date',\n",
       " 'da ': 'the',\n",
       " 'da2 ': 'Dragon Age 2',\n",
       " 'dadt ': \"Don't ask. Don't tell.\",\n",
       " 'dafs ': 'do a fuking search',\n",
       " 'dafuq ': 'What the fuk',\n",
       " 'dah ': 'dumb as hell',\n",
       " 'daii ': 'day',\n",
       " 'damhik ': \"don't ask me how I know\",\n",
       " 'damhikijk ': \"Don't Ask Me How I Know - I Just Know\",\n",
       " 'damhikt ': \"don't ask me how I know this\",\n",
       " 'dass ': 'dumb ass',\n",
       " 'dat ': 'that',\n",
       " 'dats ': \"that's\",\n",
       " 'dawg ': 'Friend',\n",
       " 'dayum ': 'damn!',\n",
       " 'dayumm ': 'damn!!',\n",
       " 'db ': 'database',\n",
       " 'db4l ': 'drinking buddy for life',\n",
       " 'dbab ': \"don't be a bitch\",\n",
       " 'dbafwtt ': \"Don't Be A Fool Wrap The Tool\",\n",
       " 'dbag ': 'douchebag',\n",
       " 'dbeyr ': \"don't believe everything you read\",\n",
       " 'dbg ': \"don't be gay\",\n",
       " 'dbh ': \"don't be hating\",\n",
       " 'dbi ': \"Don't Beg It\",\n",
       " 'dbm ': \"don't bother me\",\n",
       " 'dbz ': 'DragonBall Z',\n",
       " 'dc ': \"don't care\",\n",
       " \"dc'd \": 'disconnected',\n",
       " 'dctnry ': 'dictionary',\n",
       " 'dcw ': 'Doing Class Work',\n",
       " 'dd ': \"don't die\",\n",
       " 'ddf ': 'Drug and Disease Free',\n",
       " 'ddg ': 'Drop Dead Gorgeous',\n",
       " 'ddl ': 'direct download',\n",
       " 'ddos ': 'Distributed Denial of Service',\n",
       " 'ddr ': 'dance dance revolution',\n",
       " 'ddt ': \"Don't do that\",\n",
       " 'ded ': 'Dead',\n",
       " 'deets ': 'details',\n",
       " 'deez ': 'these',\n",
       " 'def ': 'definitely',\n",
       " 'defs ': 'definetly',\n",
       " 'degmt ': \"Don't Even Give Me That\",\n",
       " 'dem ': 'them',\n",
       " 'der ': 'there',\n",
       " 'dernoe ': \"I don't know\",\n",
       " 'detai ': \"don't even think about it\",\n",
       " 'dewd ': 'Dude',\n",
       " 'dey ': 'they',\n",
       " 'df ': 'Dumb fuck',\n",
       " 'dfc ': \"DON'T fuckING CARE\",\n",
       " 'dfo ': 'dumb fucking operator',\n",
       " 'dftba ': \"don't forget to be awesome\",\n",
       " 'dftc ': 'down for the count',\n",
       " 'dfu ': \"don't fuck up\",\n",
       " 'dfw ': 'down for whatever',\n",
       " 'dfw/m ': \"Don't fuck with Me\",\n",
       " 'dfwm ': \"Don't fuck with Me\",\n",
       " 'dfwmt ': \"Don't fucking waste my time\",\n",
       " 'dg ': \"don't go\",\n",
       " 'dga ': \"don't go anywhere\",\n",
       " 'dgac ': \"don't give a crap\",\n",
       " 'dgaf ': \"don't give a fuck\",\n",
       " 'dgara ': \"don't give a rats ass\",\n",
       " 'dgas ': \"Don't give a shit\",\n",
       " 'dgms ': \"Don't get me started\",\n",
       " 'dgoai ': \"don't go on about it\",\n",
       " 'dgt ': \"don't go there\",\n",
       " 'dgu ': \"don't give up\",\n",
       " 'dgypiab ': \"don't get your panties in a bunch\",\n",
       " 'dh ': 'dickhead',\n",
       " 'dhac ': \"Don't have a clue\",\n",
       " 'dhcp ': 'Dynamic Host Configuration Protocol',\n",
       " 'dhly ': 'does he like you',\n",
       " 'dhv ': 'Demonstration of Higher Value',\n",
       " 'diacf ': 'die in a car fire',\n",
       " 'diaf ': 'die in a fire',\n",
       " 'diah ': 'die in a hole',\n",
       " 'dic ': 'do i care',\n",
       " 'dick ': 'penis',\n",
       " 'diez ': 'dies',\n",
       " 'diff ': 'difference',\n",
       " 'dih ': 'dick in hand',\n",
       " 'dikhed ': 'dickhead',\n",
       " 'diku ': 'do i know you',\n",
       " 'diky ': 'Do I know you',\n",
       " 'dil ': 'Daughter in law',\n",
       " 'dilf ': \"dad i'd like to fuck\",\n",
       " 'dillic ': 'Do I look like I care',\n",
       " 'dillifc ': 'do I look like I fucking care',\n",
       " 'dilligad ': 'do I look like I give a damn',\n",
       " 'dilligaf ': 'do I look like I give a fuck',\n",
       " 'dilligas ': 'do i look like i give a shit',\n",
       " 'din ': \"didn't\",\n",
       " \"din't \": \"didn't\",\n",
       " 'dirl ': 'Die in real life',\n",
       " 'dis ': 'this',\n",
       " 'dit ': 'Details in Thread',\n",
       " 'diy ': 'do it yourself',\n",
       " 'dju ': 'did you',\n",
       " 'dk ': \"don't know\",\n",
       " 'dkdc ': \"don't know, don't care\",\n",
       " 'dl ': 'download',\n",
       " 'dlf ': 'dropping like flies',\n",
       " 'dlibu ': 'Dont let it bother you',\n",
       " ...}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_dicts(*dict_args):\n",
    "    \"\"\"\n",
    "    Given any number of dicts, shallow copy and merge into a new dict,\n",
    "    precedence goes to key value pairs in latter dicts.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for dictionary in dict_args:\n",
    "        result.update(dictionary)\n",
    "    return result\n",
    "\n",
    "slang_dict = merge_dicts(slang_dict_one, slang_dict_two, slang_dict_three, slang_dict_four)\n",
    "slang_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_that_hurt = {\n",
    "    'bitch': 'Targets and dehumanizes women, even if used toward men, including queer and gay men. Devalues women and femininity. Reinforces sexism.',\n",
    "    'ghetto' :'Describes something or someone as cheap, worn out, poor, dangerous, etc. Reference to housing communities that are impoverished and disproportionately impact people of color. Associates people of color with these negative characteristics.',\n",
    "    'ratchett':'Describes something or someone as cheap, worn out, poor, dangerous, etc. Reference to housing communities that are impoverished and disproportionately impact people of color. Associates people of color with these negative characteristics.',\n",
    "    'illegal alien': 'Reduces undocumented immigrants to something less than human. Fixates on legal status instead of people as individuals. Asserts that some people belong here more than others do. Ignores political, social, and economic factors that impact people of color.',\n",
    "    'no homo': 'Stresses the speaker\\'s heterosexuality, masculinity, and/or other traits to avoid being perceived as LGBTQIA. Goes to great lengths to avoid association with anything queer. Reinforces that to be LGBTQIA is bad.',\n",
    "    'retarded': 'Targets mental, emotional and physical disabilities as objects for ridicule. Used as synonyms for \"worthless,\" \"bad,\" \"unintelligent,\" \"incapable,\" etc.',\n",
    "    'lame': 'Targets mental, emotional and physical disabilities as objects for ridicule. Used as synonyms for \"worthless,\" \"bad,\" \"unintelligent,\" \"incapable,\" etc.',\n",
    "    'crazy':'Targets mental, emotional and physical disabilities as objects for ridicule. Used as synonyms for \"worthless,\" \"bad,\" \"unintelligent,\" \"incapable,\" etc.',\n",
    "    'dumb': 'Targets mental, emotional and physical disabilities as objects for ridicule. Used as synonyms for \"worthless,\" \"bad,\" \"unintelligent,\" \"incapable,\" etc.',\n",
    "    'that\\'s so gay': 'Stigmatizes gay and queer people. Uses their identities to describe something as undesirable and bad. Replaces negative adjectives with words related to LGBTQIA identities.',\n",
    "    'whore': 'Dismisses anyone seen as being \"too\" sexual, particularly sex workers, women, LGBTQI people and people of color. Perpetuates negativity toward sex itself. Regulates who is allowed to have it.',\n",
    "    'ho': 'Dismisses anyone seen as being \"too\" sexual, particularly sex workers, women, LGBTQI people and people of color. Perpetuates negativity toward sex itself. Regulates who is allowed to have it.',\n",
    "    'slut': 'Dismisses anyone seen as being \"too\" sexual, particularly sex workers, women, LGBTQI people and people of color. Perpetuates negativity toward sex itself. Regulates who is allowed to have it.',\n",
    "    'Bisexuality doesn\\'t really exist. People are just gay or straight.': 'This denies the fluidity of sexuality and dismisses people\\'s experiences and definitions of self. People deserve the right to define their own identities any way they wish and have those definitions honored.',\n",
    "    'i think everyone is bisexual': 'While this is often meant to acknowledge the fluidity of sexuality, it dismisses the reality of people who identify as bisexual and erases their experiences. It also invalidates the self-identifications of non-bisexual people.',\n",
    "    'You\\'re too femme to be bisexual':'Gender presentation does not indicate sexual orientation. Bisexual people have a wide range of gender presentations.',\n",
    "    'You\\'re too butch to be bisexual':'Gender presentation does not indicate sexual orientation. Bisexual people have a wide range of gender presentations.',\n",
    "    'Bisexual people just want straight privilege':'Bisexual people experience discrimination within straight communities and lesbian/gay communities. They never fully experience straight privilege because they do not identify as straight. Often their identities are made invisible and denied.',\n",
    "    'Bisexual people are just greedy and want to have sex with everyone.':'This stereotypes bisexual people and assumes they are all promiscuous - and that this is a bad thing. It creates negative attitudes toward sex and works against creating a sex positive climate. It also demonstrates an underlying belief that bisexuality is only about behavior and is not a legitimate identity.',\n",
    "    'Who do you see yourself ending up with?':'This is another way of implying one has to \"end up\" gay or straight and ignores bisexuality as an identity versus a relationship status. It also assumes everyone desires to be in a long-term monogamous relationship.',\n",
    "    'Tranny':'Whether or not someone identifies as trans*, calling anyone \"tranny\" is extremely offensive. While some folks within the trans* community may choose to reclaim this word for themselves, it is not a word that is okay to use to label another person or use as a joke.',\n",
    "    'That person doesn\\'t really look like a woman':'What does it mean to look like a man or woman? There are no set criteria. It also should not be assumed that all Trans Men strive to fit within dominant ideas of masculinity or all Trans Women strive to fit within dominant ideas of femininity, or that all Trans* people want to look like men or women. Gender presentation is fluid and distinct from gender identity, and all forms of gender expression deserve affirmation.',\n",
    "    'That person doesn\\'t really look like a man':'What does it mean to look like a man or woman? There are no set criteria. It also should not be assumed that all Trans Men strive to fit within dominant ideas of masculinity or all Trans Women strive to fit within dominant ideas of femininity, or that all Trans* people want to look like men or women. Gender presentation is fluid and distinct from gender identity, and all forms of gender expression deserve affirmation.',\n",
    "    'What is your REAL name? I mean the one you were given at birth':'This implies that the person\\'s gender identity and chosen name are not \"real\" and perpetuates the idea of Trans people as deceptive. It removes agency and any right to make decisions for themselves, and is incredibly invalidating. It presumes a right to intimate information, disregards privacy, and places Trans lives on public display.',\n",
    "    'He-She':'This hyphenated term is demeaning and invalidates an individual\\'s identity and the pronouns that they use.',\n",
    "    'What are you REALLY? Have you had surgery?': 'Asking anyone personal questions about their bodies and/or surgeries is invasive and inappropriate. We don\\'t ask cisgender people about what is under their clothes; we shouldn\\'t ask Trans* people either.',\n",
    "    'cunt':'Using words that refer to people with vaginas to express that someone is weak or emotional. Dehumanizes womxn and perpetuates misogyny and sexism.',\n",
    "    'twat':'Using words that refer to people with vaginas to express that someone is weak or emotional. Dehumanizes womxn and perpetuates misogyny and sexism.',\n",
    "    'pussy':'Using words that refer to people with vaginas to express that someone is weak or emotional. Dehumanizes womxn and perpetuates misogyny and sexism.',\n",
    "    'thot':'Word created to express womxn or people who are sexually promiscuous. There are speculations that the word comes from the KKK organization that referred to Black women who were forced into prostitution (i.e. Sarah Baartman: Hottentot).',\n",
    "    'ugly':'Word used to put down someone for the way they look, can be connected back to white supremacist, ableist, sizeist standards of beauty.',\n",
    "    'you guys':'Erases the identities of people who are in the room. Generalizing a group of people to be masculine.',\n",
    "    'I\\'m being such a fat-ass':'Demeans and devalues fatness/fat bodies, reinforces harmful assumptions that fat people are gluttonous and are fat because they have no restraint around food. Also implies that there is an acceptable amount of food to eat and anything more is disgusting, or that enjoying food too much is disgusting.',\n",
    "    'I\\'m being so fat right now!':'Demeans and devalues fatness/fat bodies, reinforces harmful assumptions that fat people are gluttonous and are fat because they have no restraint around food. Also implies that there is an acceptable amount of food to eat and anything more is disgusting, or that enjoying food too much is disgusting.'\n",
    "}\n",
    "\n",
    "hurtfulWords = list(words_that_hurt.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary Feature #6 1) ID tweets with female pronouns 2) Check if these words are in the tweet \n",
    "\n",
    "#these words are used disproportionately often against women\n",
    "#the behaviour they describe often goes unremarked in men.\n",
    "#source: http://sacraparental.com/2016/05/14/everyday-misogyny-122-subtly-sexist-words-women/\n",
    "#EVERYDAY MISOGYNY: 122 SUBTLY SEXIST WORDS ABOUT WOMEN (AND WHAT TO DO ABOUT THEM)\n",
    "female_and_nongender_Pronouns = set(['you','she','its','their','yours',\n",
    "                                    'her', 'it', 'they', 'them',\n",
    "                                    'yourself', 'herself', 'themselves',\n",
    "                                    'your','hers'])\n",
    "\n",
    "pronouns = {'I': ('personal', True, 'first'),\n",
    " 'me': ('personal', True, 'first'),\n",
    " 'we': ('personal', False, 'first'),\n",
    " 'us': ('personal', False, 'first'),\n",
    " 'you': ('personal', False, 'second'),\n",
    " 'she': ('personal', True, 'third'),\n",
    " 'he': ('personal', True, 'third'),\n",
    " 'her': ('possessive', True, 'third'),\n",
    " 'him': ('personal', True, 'third'),\n",
    " 'it': ('personal', True, 'third'),\n",
    " 'they': ('personal', False, 'third'),\n",
    " 'them': ('personal', False, 'third'),\n",
    " 'myself': ('reflexive', True, 'first'),\n",
    " 'ourselves': ('reflexive', False, 'first'),\n",
    " 'yourself': ('reflexive', True, 'second'),\n",
    " 'yourselves': ('reflexive', False, 'second'),\n",
    " 'himself': ('reflexive', True, 'third'),\n",
    " 'herself': ('reflexive', True, 'third'),\n",
    " 'itself': ('reflexive', True, 'third'),\n",
    " 'themselves': ('reflexive', False, 'third'),\n",
    " 'my': ('possessive', True, 'first'),\n",
    " 'your': ('possessive', False, 'second'),\n",
    " 'his': ('possessive', True, 'third'),\n",
    " 'hers': ('possessive', True, 'third'),\n",
    " 'its': ('possessive', True, 'third'),\n",
    " 'our': ('possessive', False, 'first'),\n",
    " 'their': ('possessive', False, 'third'),\n",
    " 'mine': ('possessive', True, 'first'),\n",
    " 'yours': ('possessive', False, 'second'),\n",
    " 'ours': ('possessive', False, 'first')}\n",
    "\n",
    "female_offensive = ['bossy', 'abrasive', 'ball-buster', 'aggressive', \n",
    "'shrill', 'bolshy', 'intense', 'stroppy', 'forward', \n",
    "'mannish', 'gossipy', 'Dramatic', 'Drama Queen', 'Catty', \n",
    "'Bitchy', 'Nag', 'Cold', 'Ice queen', 'Shrew', 'Humourless',\n",
    "'Man-hater', 'Banshee', 'Fishwife', 'Lippy', 'Ditzy', 'Feminazi', \n",
    "'militant feminist', 'Bridezilla', 'Diva', 'Prima donna', 'Blonde moment',\n",
    "'Feisty', 'Supermum','Working mother', 'Career woman', 'Yummy mummy', 'Little old lady', \n",
    "'WAHM', 'Slut', 'Trollop','Frigid','Easy','Tease','Loose','Man-eater','Cougar',\n",
    "'Asking for it','prude','the town bike', 'Mutton dressed as lamb','Slutty','Curvy','Mumsy',\n",
    "'Cheap','That dress is flattering','Frumpy','Let herself go','Faded beauty','Mousey',\n",
    " 'Plus-size','Clotheshorse','Brunette ','Ladylike','Bubbly','Vivacious','Flirty',\n",
    "'Sassy','Chatty','Demure','Modest','Emotional','Hysterical','Hormonal',\n",
    "'Menstrual ',' pre-menstrual ','Flaky','Moody','Over-sensitive',\n",
    "'Clucky','Neurotic','Irrational','Baby brain','Baby weight','Mummy blogger',\n",
    "'Female engineer','That’s good, for a girl','Like a girl','run like a girl', \n",
    "'throw like a girl','Mumpreneur','Spinster','Barren','She wears the pants','Housewife',\n",
    "'Houseproud','Soccer mom','Mistress','Kept woman','Incompetent cervix',\n",
    "'Failure to progress','Elderly primagravida','Irritable uterus','Tomboy',\n",
    "'Girly','a girly girl','Little lady','Jail-bait','Heart-breaker',\n",
    "'pretty little thing','Catfight','Mommy wars','Caring','Compassionate','Hard-working',\n",
    "'Conscientious','Dependable','Diligent','Dedicated','Tactful','Interpersonal','Warm',\n",
    "'Helpful','Maternal', 'Princess', 'Heart-breaker']\n",
    "#most tweeted to Megyn Kelly by Trump and trump supperters\n",
    "#https://www.vox.com/2016/1/27/10852876/donald-trump-supporters-sexist-tweets-megyn-kelly\n",
    "trump_suppporters_megynKelly = [\"ugly\", \"cheap\", 'bitch', 'whore', 'bimbo',\n",
    "                                'cunt', 'hooker', 'slut', 'skank']\n",
    "others = ['hoe', 'pussy', 'bitches', 'fatty', 'fatass', 'fat-ass']\n",
    "offsensive_words_toward_women = female_offensive + trump_suppporters_megynKelly + others + hurtfulWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_offensive_words = set()\n",
    "for word in offsensive_words_toward_women:\n",
    "    female_offensive_words.add(word.lower())\n",
    "#female_offensive_words\n",
    "\n",
    "def check_offensive_to_women(text):\n",
    "    #split tweet by white space and make lower case\n",
    "    li = set([word.lower() for word in text.split()]) \n",
    "    isFemale = female_and_nongender_Pronouns.intersection(li)\n",
    "    if len(isFemale) == 0:\n",
    "        return 0\n",
    "    isOffensive = female_offensive_words.intersection(li)\n",
    "    if isOffensive:\n",
    "        return len(isOffensive)\n",
    "    return 0\n",
    "    \n",
    "#checkOffensive = check_offensive_to_women(\"She is so hoe bossy\")\n",
    "#checkOffensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "nrc_emotions_df = pd.read_csv(\"nrc_emotions.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NRC emotions \n",
    "Read in nrc_emotions_df as list values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "anger = nrc_emotions_df.loc[nrc_emotions_df['anger']][['term']].values\n",
    "anticipation = nrc_emotions_df.loc[nrc_emotions_df['anticipation']][['term']].values\n",
    "disgust = nrc_emotions_df.loc[nrc_emotions_df['disgust']][['term']].values\n",
    "fear = nrc_emotions_df.loc[nrc_emotions_df['fear']][['term']].values\n",
    "joy = nrc_emotions_df.loc[nrc_emotions_df['joy']][['term']].values\n",
    "sadness = nrc_emotions_df.loc[nrc_emotions_df['sadness']][['term']].values\n",
    "surprise = nrc_emotions_df.loc[nrc_emotions_df['surprise']][['term']].values\n",
    "trust = nrc_emotions_df.loc[nrc_emotions_df['trust']][['term']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "def anger_count(text):\n",
    "    s = tknzr.tokenize(text)\n",
    "    score = sum(map(lambda word : 1 if word in anger else 0, s))\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "def anticipation_count(text):\n",
    "    s = tknzr.tokenize(text)\n",
    "    score = sum(map(lambda word : 1 if word in anticipation else 0, s))\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "def disgust_count(text):\n",
    "    s = tknzr.tokenize(text)\n",
    "    score = sum(map(lambda word : 1 if word in disgust else 0, s))\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "def joy_count(text):\n",
    "    s = tknzr.tokenize(text)\n",
    "    score = sum(map(lambda word : 1 if word in joy else 0, s))\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "def fear_count(text):\n",
    "    s = tknzr.tokenize(text)\n",
    "    score = sum(map(lambda word : 1 if word in fear else 0, s))\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "def sadness_count(text):\n",
    "    s = tknzr.tokenize(text)\n",
    "    score = sum(map(lambda word : 1 if word in sadness else 0, s))\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "def surprise_count(text):\n",
    "    s = tknzr.tokenize(text)\n",
    "    score = sum(map(lambda word : 1 if word in surprise else 0, s))\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "def trust_count(text):\n",
    "    s = tknzr.tokenize(text)\n",
    "    score = sum(map(lambda word : 1 if word in trust else 0, s))\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can use the TFIDF vectorizer to get a token matrix for the POS tags\n",
    "pos_vectorizer = TfidfVectorizer(\n",
    "    tokenizer=None,\n",
    "    lowercase=False,\n",
    "    preprocessor=None,\n",
    "    ngram_range=(1, 3),\n",
    "    stop_words=None,\n",
    "    use_idf=False,\n",
    "    smooth_idf=False,\n",
    "    norm=None,\n",
    "    decode_error='replace',\n",
    "    max_features=5000,\n",
    "    min_df=5,\n",
    "    max_df=0.75,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct POS TF matrix and get vocab dict\n",
    "pos = pos_vectorizer.fit_transform(pd.Series(tweet_tags)).toarray()\n",
    "pos_vocab = {v:i for i, v in enumerate(pos_vectorizer.get_feature_names())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_twitter_objs(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "    4) hashtags with HASHTAGHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned.\n",
    "    \n",
    "    Returns counts of urls, mentions, and hashtags.\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    hashtag_regex = '#[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, 'URLHERE', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, 'MENTIONHERE', parsed_text)\n",
    "    parsed_text = re.sub(hashtag_regex, 'HASHTAGHERE', parsed_text)\n",
    "    return(parsed_text.count('URLHERE'),parsed_text.count('MENTIONHERE'),parsed_text.count('HASHTAGHERE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def other_features(tweet):\n",
    "    \"\"\"This function takes a string and returns a list of features.\n",
    "    These include Sentiment scores, Text and Readability scores,\n",
    "    as well as Twitter specific features\"\"\"\n",
    "    #sentiment = sentiment_analyzer.polarity_scores(tweet)\n",
    "    \n",
    "    words = preprocess(tweet) #Get text only\n",
    "    \n",
    "    syllables = textstat.syllable_count(words)\n",
    "    num_chars = sum(len(w) for w in words)\n",
    "    num_chars_total = len(tweet)\n",
    "    num_terms = len(tweet.split())\n",
    "    num_words = len(words.split())\n",
    "    #avg_syl = round(float((syllables+0.001))/float(num_words+0.001),4)\n",
    "    num_unique_terms = len(set(words.split()))\n",
    "    #Our features\n",
    "    targeted = contains_target(words)\n",
    "    immigrant_ref = 0\n",
    "    if words.find('immigrant') or words.find('immigrants'):\n",
    "        immigrant_ref = 1\n",
    "    isOffensiveToWomen = check_offensive_to_women(tweet)\n",
    "    \n",
    "    ###Modified FK grade, where avg words per sentence is just num words/1\n",
    "    #FKRA = round(float(0.39 * float(num_words)/1.0) + float(11.8 * avg_syl) - 15.59,1)\n",
    "    ##Modified FRE score, where sentence fixed to 1\n",
    "    #FRE = round(206.835 - 1.015*(float(num_words)/1.0) - (84.6*float(avg_syl)),2)\n",
    "    \n",
    "    twitter_objs = count_twitter_objs(tweet)\n",
    "    retweet = 0\n",
    "    if \"rt\" in words:\n",
    "        retweet = 1\n",
    "        \n",
    "    features = [num_chars, num_chars_total, num_terms, num_words,\n",
    "                num_unique_terms,\n",
    "                twitter_objs[2], twitter_objs[1],\n",
    "                twitter_objs[0], retweet, targeted, immigrant_ref, isOffensiveToWomen]\n",
    "    #features = pandas.DataFrame(features)\n",
    "    return features\n",
    "\n",
    "def get_feature_array(tweets):\n",
    "    feats=[]\n",
    "    for t in tweets:\n",
    "        feats.append(other_features(t))\n",
    "    return np.array(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = open('ethnic_groups.txt','r').read().split('\\n')\n",
    "\n",
    "#demonstrative adjectives and other words that can inidicate targeting of a specific group\n",
    "targets = ['all', 'every', 'you', 'those', 'these', 'any', 'each', 'no', 'that', 'this', ]\n",
    "modality = ['should', 'can', 'can\\'t', 'cannot', 'won\\'t', 'will', 'want']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If tweet contains a targeted statement referring to a certain group, i.e. \"all you Asians\" or \"every Mexican\"\n",
    "#also checks if a group word is followed by some sort of modal verb\n",
    "\n",
    "def contains_target(words):\n",
    "    for i in range(len(words)):\n",
    "        if words[i].lower() in targets:\n",
    "            if words[i+1].lower() in groups:\n",
    "                return 1\n",
    "        if words[i].lower() in groups:\n",
    "            if words[i+1].lower() in modality:\n",
    "                return 1\n",
    "            \n",
    "    return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_features_names = [\"num_chars\", \"num_chars_total\", \"num_terms\", \"num_words\", \"num_unique_words\", \"num_hashtags\", \\\n",
    "                    \"num_mentions\", \"num_urls\", \"is_retweet\", \"targeted\", \"immigrant_ref\", \"isOffensiveToWomen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = get_feature_array(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19746"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN FROM HERE WITHOUT ELMO AND BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X = tweets\n",
    "all_y = df['class'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now join them all up\n",
    "#M = np.concatenate([tfidf,pos,feats,X_elmo_train_layers],axis=1)\n",
    "\n",
    "M = np.concatenate([tfidf,pos,feats],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally get a list of variable names\n",
    "variables = ['']*len(vocab)\n",
    "for k,v in vocab.items():\n",
    "    variables[v] = k\n",
    "\n",
    "pos_variables = ['']*len(pos_vocab)\n",
    "for k,v in pos_vocab.items():\n",
    "    pos_variables[v] = k\n",
    "\n",
    "feature_names = variables+pos_variables+other_features_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(M)\n",
    "y = df['class'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "        [('select', SelectFromModel(LogisticRegression(class_weight='balanced',\n",
    "                                                  penalty=\"l1\", C=0.01))),\n",
    "        ('model', LogisticRegression(class_weight='balanced',penalty='l2'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{}] # Optionally add parameters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipe, \n",
    "                           param_grid,\n",
    "                           cv=StratifiedKFold(n_splits=5, \n",
    "                                              random_state=42).split(X_train, y_train), \n",
    "                           verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=   5.7s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=   5.4s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   4.2s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.7s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   27.6s finished\n"
     ]
    }
   ],
   "source": [
    "model = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.42      0.34       104\n",
      "           1       0.92      0.86      0.89      1507\n",
      "           2       0.68      0.76      0.72       364\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1975\n",
      "   macro avg       0.63      0.68      0.65      1975\n",
      "weighted avg       0.84      0.82      0.83      1975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report( y_test, y_preds )\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without isOffensiveToWomen\n",
    "#              precision    recall  f1-score   support\n",
    "\n",
    "#           0       0.29      0.43      0.35       104\n",
    "#           1       0.92      0.86      0.89      1507\n",
    "#           2       0.68      0.75      0.71       364\n",
    "\n",
    "#   micro avg       0.82      0.82      0.82      1975\n",
    "#   macro avg       0.63      0.68      0.65      1975\n",
    "#weighted avg       0.84      0.82      0.83      1975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With binary isOffensive\n",
    "#with is offensiveToWomen\n",
    "#             precision    recall  f1-score   support\n",
    "\n",
    "#           0       0.28      0.42      0.34       104\n",
    "#           1       0.92      0.86      0.89      1507\n",
    "#           2       0.67      0.76      0.71       364\n",
    "\n",
    "#   micro avg       0.82      0.82      0.82      1975\n",
    "#   macro avg       0.62      0.68      0.64      1975\n",
    "#weighted avg       0.84      0.82      0.83      1975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = df[['tweet', 'class']]\n",
    "misses = np.where(np.asarray(y_test) != y_preds)\n",
    "missed_preds = []\n",
    "for i in range(len(y_test)):\n",
    "    if np.asarray(y_test)[i] != y_preds[i]:\n",
    "        missed_preds.append(y_preds[i])\n",
    "    \n",
    "\n",
    "missed = [list(y_test.index)[i] for i in misses[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_tweets = all_tweets.iloc[missed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8500</th>\n",
       "      <td>@TonyO97 fuck i look like shopping at that tra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>RT @DessantiGina: @TonyJRodriguez @WolfVanHale...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15306</th>\n",
       "      <td>Damn some Oreos would be so fucking clutch rig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>Dis nicca lame</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6956</th>\n",
       "      <td>@DivaMonRoe2uHoE @CheefPolo hoe hoe hoe, merry...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7172</th>\n",
       "      <td>Gonna straight hip check the next hillbilly wh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19415</th>\n",
       "      <td>They're calling it #Sandy because the wind is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>I really just want to kill some towel head ter...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10399</th>\n",
       "      <td>@operationSAFE @GaltsGirl lived there and can ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7983</th>\n",
       "      <td>do they even make dresses any more that have s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13326</th>\n",
       "      <td>Good even-ink, honkies!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9397</th>\n",
       "      <td>RT @WORIDSTARHlPHOP: this kid definitely got t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>@Cee_Murda94 it's almost ya fucking birthday. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14040</th>\n",
       "      <td>&amp;#8220;@AustinMahone: just got a new fish it's...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10989</th>\n",
       "      <td>@kieffer_jason keep talking I'm going to make ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11152</th>\n",
       "      <td>Young Gem &amp;amp; Don Chief been killing it in t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14629</th>\n",
       "      <td>@Ants_SNEweather Well you got to see pom-pom Pete</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>This cowboys an redskins game was a hell of a ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3018</th>\n",
       "      <td>How long are they going to let the fools in #F...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13317</th>\n",
       "      <td>Well now that I'm basically gone full retard, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4202</th>\n",
       "      <td>@yoKBFILTHY shit is trash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18849</th>\n",
       "      <td>guess rubes doesn't want to go on a date with ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>RT @elchavaloko: I can see moose rockin himsel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>RT @__thaRealist: @Dono_44 yea that hoe was ro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17348</th>\n",
       "      <td>@joeylattime @Mawson38 @ameriC00N thats just m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16171</th>\n",
       "      <td>#creamteam leaving hoes w #cockbreath</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13270</th>\n",
       "      <td>@charloosss @keepitplur @nicoleariel_ I'll chu...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>Told my dad to go buy cookies for the graduati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4045</th>\n",
       "      <td>I just can't date a ghetto ass girl bruh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10904</th>\n",
       "      <td>Touchdown hoe ... touchdown hoe!!!!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3410</th>\n",
       "      <td>Let's just say the hotel I've been staying at ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15535</th>\n",
       "      <td>RT @KidnapYoGranny: if u dont want your heart ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>RT @exjon: Before covering up #IRS misdeeds, c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3449</th>\n",
       "      <td>in real life and online I follow that. sorry f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6244</th>\n",
       "      <td>@Prophzilla before I went off to college I wan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10534</th>\n",
       "      <td>I'm sorry.. I'm sorry.. I can't fuc wit u no m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13302</th>\n",
       "      <td>Happy birthday to the biggest retard out there...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5436</th>\n",
       "      <td>#BlessJesus The #Crown of HIS head to the sole...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18516</th>\n",
       "      <td>RT @TheDouch3: Tweeting about ur boyfriend won...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6161</th>\n",
       "      <td>@penisgravy \\nIs dem? I wants to has my weenis...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12325</th>\n",
       "      <td>RT @BadNewsAli: You really are a faggot if you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17103</th>\n",
       "      <td>RT @__bettyboo: You better pray I don't send y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14625</th>\n",
       "      <td>hoes pick me like dandelions #PickMe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16425</th>\n",
       "      <td>@Ray_Lakee #fag\\n Fuckin pirelli tire black as...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>I'm a wigger</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11719</th>\n",
       "      <td>@sassyharryballs ugly white bitch</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15238</th>\n",
       "      <td>RT @TransaparenT: \"Hi mom, last night I was cu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7562</th>\n",
       "      <td>@triple6em96 @Hunglikerobby_ uh I think his mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847</th>\n",
       "      <td>&amp;#8220;@Garricka_: Ima just block you hoes out...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>@Huntermoore finger my pussy slowly with circu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12416</th>\n",
       "      <td>Take that and shove it up your ass, @KeithOlbe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5140</th>\n",
       "      <td>Fake niccas ain't far dog they right in ya face!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16615</th>\n",
       "      <td>@almuirSI Probably, yeah. By most accounts, he...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13142</th>\n",
       "      <td>You out there popping them pills fucking them ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19191</th>\n",
       "      <td>I can tell when certain and specific people ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14037</th>\n",
       "      <td>@khamillkilroy &amp;#128514;&amp;#128514; Shy Glizzy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7588</th>\n",
       "      <td>RT @FoodPornsx: Deep Fried Oreos &amp;#128588;&amp;#12...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3068</th>\n",
       "      <td>RT @SSparklesDaily: The most beautiful women I...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>RT @_LilBaddiee_: I have a daughter to think a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6503</th>\n",
       "      <td>@InfidelAlie that should read suck on my bacon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  class\n",
       "8500   @TonyO97 fuck i look like shopping at that tra...      1\n",
       "2626   RT @DessantiGina: @TonyJRodriguez @WolfVanHale...      0\n",
       "15306  Damn some Oreos would be so fucking clutch rig...      1\n",
       "1739                                      Dis nicca lame      2\n",
       "6956   @DivaMonRoe2uHoE @CheefPolo hoe hoe hoe, merry...      2\n",
       "7172   Gonna straight hip check the next hillbilly wh...      1\n",
       "19415  They're calling it #Sandy because the wind is ...      1\n",
       "5116   I really just want to kill some towel head ter...      0\n",
       "10399  @operationSAFE @GaltsGirl lived there and can ...      2\n",
       "7983   do they even make dresses any more that have s...      1\n",
       "13326                            Good even-ink, honkies!      1\n",
       "9397   RT @WORIDSTARHlPHOP: this kid definitely got t...      1\n",
       "2189   @Cee_Murda94 it's almost ya fucking birthday. ...      1\n",
       "14040  &#8220;@AustinMahone: just got a new fish it's...      2\n",
       "10989  @kieffer_jason keep talking I'm going to make ...      1\n",
       "11152  Young Gem &amp; Don Chief been killing it in t...      1\n",
       "14629  @Ants_SNEweather Well you got to see pom-pom Pete      2\n",
       "4991   This cowboys an redskins game was a hell of a ...      2\n",
       "3018   How long are they going to let the fools in #F...      2\n",
       "13317  Well now that I'm basically gone full retard, ...      1\n",
       "4202                           @yoKBFILTHY shit is trash      1\n",
       "18849  guess rubes doesn't want to go on a date with ...      2\n",
       "1710   RT @elchavaloko: I can see moose rockin himsel...      1\n",
       "1580   RT @__thaRealist: @Dono_44 yea that hoe was ro...      1\n",
       "17348  @joeylattime @Mawson38 @ameriC00N thats just m...      0\n",
       "16171              #creamteam leaving hoes w #cockbreath      1\n",
       "13270  @charloosss @keepitplur @nicoleariel_ I'll chu...      2\n",
       "2740   Told my dad to go buy cookies for the graduati...      0\n",
       "4045            I just can't date a ghetto ass girl bruh      1\n",
       "10904               Touchdown hoe ... touchdown hoe!!!!!      1\n",
       "...                                                  ...    ...\n",
       "3410   Let's just say the hotel I've been staying at ...      2\n",
       "15535  RT @KidnapYoGranny: if u dont want your heart ...      0\n",
       "2498   RT @exjon: Before covering up #IRS misdeeds, c...      1\n",
       "3449   in real life and online I follow that. sorry f...      0\n",
       "6244   @Prophzilla before I went off to college I wan...      1\n",
       "10534  I'm sorry.. I'm sorry.. I can't fuc wit u no m...      1\n",
       "13302  Happy birthday to the biggest retard out there...      1\n",
       "5436   #BlessJesus The #Crown of HIS head to the sole...      2\n",
       "18516  RT @TheDouch3: Tweeting about ur boyfriend won...      1\n",
       "6161   @penisgravy \\nIs dem? I wants to has my weenis...      1\n",
       "12325  RT @BadNewsAli: You really are a faggot if you...      1\n",
       "17103  RT @__bettyboo: You better pray I don't send y...      0\n",
       "14625               hoes pick me like dandelions #PickMe      1\n",
       "16425  @Ray_Lakee #fag\\n Fuckin pirelli tire black as...      1\n",
       "3106                                        I'm a wigger      1\n",
       "11719                  @sassyharryballs ugly white bitch      0\n",
       "15238  RT @TransaparenT: \"Hi mom, last night I was cu...      1\n",
       "7562   @triple6em96 @Hunglikerobby_ uh I think his mo...      1\n",
       "16847  &#8220;@Garricka_: Ima just block you hoes out...      1\n",
       "2084   @Huntermoore finger my pussy slowly with circu...      1\n",
       "12416  Take that and shove it up your ass, @KeithOlbe...      1\n",
       "5140    Fake niccas ain't far dog they right in ya face!      1\n",
       "16615  @almuirSI Probably, yeah. By most accounts, he...      2\n",
       "13142  You out there popping them pills fucking them ...      1\n",
       "19191  I can tell when certain and specific people ar...      1\n",
       "14037       @khamillkilroy &#128514;&#128514; Shy Glizzy      2\n",
       "7588   RT @FoodPornsx: Deep Fried Oreos &#128588;&#12...      2\n",
       "3068   RT @SSparklesDaily: The most beautiful women I...      2\n",
       "2712   RT @_LilBaddiee_: I have a daughter to think a...      1\n",
       "6503   @InfidelAlie that should read suck on my bacon...      0\n",
       "\n",
       "[353 rows x 2 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susanabenavidez/anaconda3/envs/nlu/lib/python3.7/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/susanabenavidez/anaconda3/envs/nlu/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(88, 205)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed_tweets.loc[:,'prediction'] = missed_preds\n",
    "len(missed_tweets[(missed_tweets['class'] == 2)]), len(missed_tweets[(missed_tweets['class'] == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with isOffensiveToWomen\n",
    "#(89, 214)\n",
    "\n",
    "#without isOffensiveToWomen\n",
    "#(90, 206)\n",
    "\n",
    "#(88, 205)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlu",
   "language": "python",
   "name": "nlu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
